#!/usr/bin/env python3

from http.client import responses
import secrets
from typing import List
import sys
import re
import subprocess
import requests
import os
import json
from urllib.request import urlretrieve
from pathlib import Path
import shutil

folders = [
    f'{os.getenv("HOME")}/storage/dcim/Sendvid',
    f'{os.getenv("HOME")}/storage/dcim/Instagram',
    f'{os.getenv("HOME")}/storage/dcim/Reddit',
    f'{os.getenv("HOME")}/storage/dcim/Tiktok',
    f'{os.getenv("HOME")}/storage/dcim/Kwai',
]

USER_AGENT = "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/86.0.4240.75 Safari/537.36"


class InstagramInfo:
    def __init__(self, cookie: str, app_id: str, www_claim: str):
        self.cookie: str = cookie
        self.app_id: str = app_id
        self.www_claim: str = www_claim

    @classmethod
    def from_file(self, file_path: str):
        if not os.path.isfile(file_path):
            raise Exception(f"file {file_path} not found!")
        with open(file_path, "r") as file:
            content = file.read()
            splittedl_lines = content.splitlines()
            envs = [tuple(line.split("=", 1)) for line in splittedl_lines]
            for env in envs:
                (key, value) = env
                os.environ[key.strip()] = value.strip()
        return InstagramInfo(
            cookie=os.getenv("COOKIE"),
            app_id=os.getenv("APP_ID"),
            www_claim=os.getenv("WWW_CLAIM"),
        )


def get_stories_instagram(url: str):
    info = InstagramInfo.from_file(".env")
    response = requests.get(
        url,
        headers={
            "Host": "www.instagram.com",
            "User-Agent": USER_AGENT,
            "Cookie": info.cookie.encode("utf-8"),
            "X-IG-App-ID": info.app_id,
        },
    )

    print("foi ate aqui")
    regx = re.compile(
        "((?:https?:)?\/\/)?((?:www|m)\.)?(?:instagram.com)\/stories\/highlights\/([0-9]{17,17})\/",
        re.IGNORECASE,
    )

    result_regx = regx.search(response.text)

    if result_regx is not None:
        id_url = regx.search(response.text).group()
        story_id = id_url[-18 : id_url.index("/", -1)]
        stories_url = f"https://i.instagram.com/api/v1/feed/reels_media/?reel_ids=highlight:{story_id}"
        response = requests.get(
            stories_url,
            headers={
                "Host": "i.instagram.com",
                "User-Agent": USER_AGENT,
                "Cookie": info.cookie.encode("utf-8"),
                "X-IG-App-ID": info.app_id,
            },
        )
        if response.status_code == 200:
            downlodable_list: List[str] = []
            json_result = json.loads(response.text)
            media_items = json_result["reels"][f"highlight:{story_id}"]["items"]
            for item in media_items:
                downlodable_list.append(instagram_result_type(item))

            for downld in downlodable_list:
                if downld == "https://static.cdninstagram.com/rsrc.php/null.jpg":
                    print("Null URL found")
                    continue
                try:
                    filename = downld.split("/")[-1].split("?")[0]
                    if filename.split(".")[-1] == "mp4":
                        urlretrieve(downld, f"{folders[1]}/{filename}")
                    else:
                        response = requests.get(downld, stream=True)
                        if response.status_code == 200:
                            response.raw.decode_content = True
                            with open(f"{folders[1]}/{filename}", "wb") as file:
                                shutil.copyfileobj(response.raw, file)
                except Exception as e:
                    print(f"Error trying to download: {e}")
                    continue


def instagram_result_type(json_obj) -> str:
    if json_obj.get("video_versions") is None:
        return json_obj["image_versions2"]["candidates"][0]["url"]
    else:
        return json_obj["video_versions"][0]["url"]


def get_instagram(url: str):
    info = InstagramInfo.from_file(".env_")
    html_page_response = requests.get(
        url,
        headers={
            "Host": "www.instagram.com",
            "User-Agent": USER_AGENT,
            "Cookie": info.cookie.encode("utf-8"),
            "sec-fetch-site": "same-origin",
            "sec-fetch-user": "?1",
            "sec-fetch-dest": "document",
            "sec-fetch-mode": "navigate",
        },
    )

    if html_page_response.status_code == 200:
        html_document = html_page_response.text
        id_match = re.search(r"media\?id=([0-9]+)", html_document)
        if id_match is not None:
            match_result = id_match.group()
            post_id = "".join([s for s in match_result if s.isdigit()])
            url = f"https://i.instagram.com/api/v1/media/{post_id}/info/"
            print(url)
            downloadable: List[str] = []
            response = requests.get(
                url,
                headers={
                    "Host": "i.instagram.com",
                    "User-Agent": USER_AGENT,
                    "Cookie": info.cookie.encode("utf-8"),
                    "X-IG-App-ID": info.app_id,
                },
            )
            if response.status_code == 200:
                json_result = json.loads(response.text)
                main_object = json_result["items"][0]
                if main_object.get("carousel_media") is None:
                    downloadable.append(instagram_result_type(main_object))
                else:
                    for media_item in main_object["carousel_media"]:
                        downloadable.append(instagram_result_type(media_item))

                for downld in downloadable:
                    if downld == "https://static.cdninstagram.com/rsrc.php/null.jpg":
                        print("Null URL found")
                        continue
                    try:
                        filename = downld.split("/")[-1].split("?")[0]
                        if filename.split(".")[-1] == "mp4":
                            urlretrieve(downld, f"{folders[1]}/{filename}")
                        else:
                            response = requests.get(downld, stream=True)
                            if response.status_code == 200:
                                response.raw.decode_content = True
                                with open(f"{folders[1]}/{filename}", "wb") as file:
                                    shutil.copyfileobj(response.raw, file)
                    except Exception as e:
                        print(f"Error trying to download: {e}")
                        continue
        else:
            print(html_document)


def get_sendvid(url: str):
    if url.find("/embed/") == -1:
        url = f'{url[:url.find(".com") + 4]}/embed{url[url.find(".com") + 4:]}'
    response = requests.get(url)
    if response.status_code == 200:
        result = re.findall(
            re.compile(r'.src=".*', re.IGNORECASE), response.content.decode("utf-8")
        )
        for regx in result:
            if str(regx).find(".m3u8") != -1:
                url_start = regx.find('"') + 1
                url_end = regx[url_start:].find("type=") + 4

                if url_start != -1 and url_end != -1:
                    url = regx[url_start:url_end]
                    cmd = f'ffmpeg -i "{url}" -bsf:a aac_adtstoasc -vcodec copy -c copy -crf 50 {folders[0]}/{secrets.token_hex(8)}.mp4'
                    proc = subprocess.call(cmd, shell=True)
                    print(f"result code: {proc}")


def get_youtube(url: str):
    cmd = f"yt-dlp {url}"
    proc = subprocess.call(cmd, shell=True)
    print(f"result code: {proc}")


def get_kwai(url: str):
    response = requests.get(
        url,
        headers={"User-Agent": USER_AGENT},
    )
    if response.status_code == 200:
        match = re.search(
            "https:\/\/ali-([a-zA-Z]{2})-cdn.kwai.net\/bs2\/newWatermark\/([a-zA-Z0-9_]+).mp4",
            response.text,
            re.MULTILINE,
        )
        if match is not None:
            video: str = match.group()
            response = requests.get(
                url=video,
                headers={"User-Agent": USER_AGENT},
                stream=True,
            )
            if response.status_code == 200:
                response.raw.decode_content = True
                video_name = video[video.rfind("/") + 1 :]
                print(video_name)
                try:
                    with open(f"{folders[4]}/{video_name}", "wb") as file:
                        for chunk in response.iter_content(chunk_size=512):
                            if chunk:
                                file.write(chunk)
                except Exception as e:
                    print(e)


def get_tiktok(url: str):
    video_id = url.split("/")[-1].split("?")[0]
    if video_id is not None or "":
        embedded_url = f"https://www.tiktok.com/embed/{video_id}"
        session = requests.Session()
        session.headers.update({"referer": embedded_url})
        response = session.get(url=embedded_url, headers={"User-Agent": USER_AGENT})
        if response.status_code == 200:
            response_trans = response.text.translate(str.maketrans('"', "\n"))
            match = re.search(
                "^https:\/\/v16-web.tiktok.com\/video\/([a-zA-Z0-9-\/\?=&%_~.]+)$",
                response_trans,
                re.MULTILINE,
            )
            if match is not None:
                video = match.group()
                response = session.get(
                    url=video,
                    headers={"User-Agent": USER_AGENT},
                    stream=True,
                )
                if response.status_code == 200:
                    response.raw.decode_content = True
                    try:
                        with open(f"{folders[3]}/{video_id}.mp4", "wb") as file:
                            for chunk in response.iter_content(chunk_size=512):
                                if chunk:
                                    file.write(chunk)
                    except Exception as e:
                        print(e)


def get_reddit(url: str):
    url = url.replace("https://www", "https://old")
    response = requests.get(
        url,
        cookies={"over18": "1"},
        headers={"User-Agent": USER_AGENT},
    )

    if response.status_code == 200:
        iterable = re.finditer(
            r"https:\/\/(preview|i|v)\.redd\.it\/([a-zA-Z0-9]+)(\.(png|jpg|gif)|\/HLSPlaylist.m3u8)\??([a-zA-Z0-9=%]+)?",
            response.text,
        )
        substring_regx = re.compile(r"\?width=(\d+)")
        links = list(set([substring_regx.sub("", link.group()) for link in iterable]))
        for link in links:
            link = link.replace("preview", "i")
            filename = link.split("/")[-1].split("?")[0]
            try:
                if filename.split(".")[-1] in ["jpg", "gif", "png"]:
                    response = requests.get(link, stream=True)
                    if response.status_code == 200:
                        response.raw.decode_content = True
                        with open(f"{folders[2]}/{filename}", "wb") as file:
                            shutil.copyfileobj(response.raw, file)
                else:
                    cmd = f'ffmpeg -i "{link}" -bsf:a aac_adtstoasc -vcodec copy -c copy -crf 50 {folders[2]}/{secrets.token_hex(8)}.mp4'
                    proc = subprocess.call(cmd, shell=True)
                    print(f"result code: {proc}")
            except Exception as e:
                print(f"Error trying to download: {e}")
                continue


exps: List[list] = [
    [
        get_sendvid,
        re.compile(
            "^(http(s)?)?:\/\/((www|m)\.)?sendvid\.com\/(embed\/)?([a-zA-Z0-9]{8,8})$",
            re.IGNORECASE,
        ),
    ],
    [
        get_youtube,
        re.compile(
            "^http(?:s?):\/\/(?:www\.)?youtu(?:be\.com\/watch\?v=|\.be\/)([\w\-\_]*)(&(amp;)?‌​[\w\?‌​=]*)?$",
            re.IGNORECASE,
        ),
    ],
    [
        get_instagram,
        re.compile(
            "^((?:https?:)?\/\/)?((?:www|m)\.)?(?:instagram.com)\/(p|reel|tv)\/([a-zA-Z0-9_.-]){11,11}(\/)?([a-zA-Z0-9_=?]+)?$",
            re.IGNORECASE,
        ),
    ],
    [
        get_reddit,
        re.compile(
            "^((?:https?:)?\/\/)(www\.)?reddit.com\/(user|r|u)\/([a-zA-Z0-9_]+)\/comments\/([\s\S\/_?=&]+)$",
            re.IGNORECASE,
        ),
    ],
    [
        get_tiktok,
        re.compile(
            "^https:\/\/(m|www)\.tiktok.com\/(embed|@[a-zA-Z0-9_.]+\/video)\/(\d{19,19})((\?)[a-zA-Z_=&\d]+)?$",
            re.IGNORECASE,
        ),
    ],
    [
        get_stories_instagram,
        re.compile(
            "^((?:https?:)?\/\/)?((?:www|m)\.)?(?:instagram.com)\/s\/([a-zA-Z0-9])+(\/)?\?([a-zA-Z0-9_=&]+)?$",
            re.IGNORECASE,
        ),
    ],
    [
        get_kwai,
        re.compile("^https:\/\/s.kw.ai\/p\/([a-zA-Z0-9]{8})$", re.IGNORECASE),
    ],
]


def main(args: List[str]) -> int:
    for folder in folders:
        Path(folder).mkdir(parents=True, exist_ok=True)

    if len(args) != 0:
        for function, exp in exps:
            if exp.match(args[0]) is not None:
                function(args[0])
                break
    return 0


if __name__ == "__main__":
    sys.exit(main(sys.argv[1:]))
